{"cells":[{"cell_type":"markdown","metadata":{"id":"sSBfdcEo02EH"},"source":["## Семинар 8: \"Современные модели для NLP\""]},{"cell_type":"markdown","metadata":{"id":"Yt2LcA_C02EJ"},"source":["ФИО: Склянный Алексей Алексеевич"]},{"cell_type":"markdown","metadata":{"id":"z87HsFGe02EK"},"source":["### На семинаре мы разберем [код трансфомера на pytorch](https://nlp.seas.harvard.edu/2018/04/03/attention.html)"]},{"cell_type":"markdown","metadata":{"id":"F0m8IOq802E8"},"source":["###  ДЗ [3 балла]"]},{"cell_type":"markdown","metadata":{"id":"U0AFMjVfmr2o"},"source":["Обратите внимание, что в этой работе вам потребуется скачать модель весом ~150MB, также ее вычисление занимает определенное время, так что рекомендуется считать эту задачу на [google colab](https://colab.research.google.com/)."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11111,"status":"ok","timestamp":1671373022933,"user":{"displayName":"Алексей Склянный","userId":"03838426136238889270"},"user_tz":-180},"id":"MycBXTf4m_JH","outputId":"04e8aebe-5926-4607-dce6-0752bbc2d952","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 48.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 61.0 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"]}],"source":["# !pip install torch\n","!pip install --upgrade transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4658,"status":"ok","timestamp":1671373027580,"user":{"displayName":"Алексей Склянный","userId":"03838426136238889270"},"user_tz":-180},"id":"Lqd1MFO-1ev0","outputId":"f136a5f0-c874-4a91-8113-8e6455ffa29e","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n"]}],"source":["!pip install tqdm"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19986,"status":"ok","timestamp":1671373047553,"user":{"displayName":"Алексей Склянный","userId":"03838426136238889270"},"user_tz":-180},"id":"6a7Twd_m09PH","outputId":"e2fa0d70-af8b-4a28-fa70-e1c176d4412b","vscode":{"languageId":"python"}},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n","  warnings.warn(\n"]}],"source":["import torch\n","from transformers import *\n","import tqdm"]},{"cell_type":"code","execution_count":63,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2848,"status":"ok","timestamp":1671375978376,"user":{"displayName":"Алексей Склянный","userId":"03838426136238889270"},"user_tz":-180},"id":"5mEU6bzh02E9","outputId":"e751ba1a-7392-41b6-9fc0-fce8869ceec9","vscode":{"languageId":"python"}},"outputs":[{"name":"stderr","output_type":"stream","text":["loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--google--mobilebert-uncased/snapshots/1f90a6c24c7879273a291d34a849033eba2dbc0f/vocab.txt\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--mobilebert-uncased/snapshots/1f90a6c24c7879273a291d34a849033eba2dbc0f/config.json\n","Model config MobileBertConfig {\n","  \"_name_or_path\": \"google/mobilebert-uncased\",\n","  \"architectures\": [\n","    \"MobileBertForPreTraining\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_activation\": false,\n","  \"classifier_dropout\": null,\n","  \"embedding_size\": 128,\n","  \"hidden_act\": \"relu\",\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 512,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 512,\n","  \"intra_bottleneck_size\": 128,\n","  \"key_query_shared_bottleneck\": true,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"mobilebert\",\n","  \"normalization_type\": \"no_norm\",\n","  \"num_attention_heads\": 4,\n","  \"num_feedforward_networks\": 4,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.25.1\",\n","  \"trigram_input\": true,\n","  \"true_hidden_size\": 128,\n","  \"type_vocab_size\": 2,\n","  \"use_bottleneck\": true,\n","  \"use_bottleneck_attention\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--mobilebert-uncased/snapshots/1f90a6c24c7879273a291d34a849033eba2dbc0f/config.json\n","Model config MobileBertConfig {\n","  \"_name_or_path\": \"google/mobilebert-uncased\",\n","  \"architectures\": [\n","    \"MobileBertForPreTraining\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_activation\": false,\n","  \"classifier_dropout\": null,\n","  \"embedding_size\": 128,\n","  \"hidden_act\": \"relu\",\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 512,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 512,\n","  \"intra_bottleneck_size\": 128,\n","  \"key_query_shared_bottleneck\": true,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"mobilebert\",\n","  \"normalization_type\": \"no_norm\",\n","  \"num_attention_heads\": 4,\n","  \"num_feedforward_networks\": 4,\n","  \"num_hidden_layers\": 24,\n","  \"pad_token_id\": 0,\n","  \"transformers_version\": \"4.25.1\",\n","  \"trigram_input\": true,\n","  \"true_hidden_size\": 128,\n","  \"type_vocab_size\": 2,\n","  \"use_bottleneck\": true,\n","  \"use_bottleneck_attention\": false,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--mobilebert-uncased/snapshots/1f90a6c24c7879273a291d34a849033eba2dbc0f/pytorch_model.bin\n","Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing MobileBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing MobileBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of MobileBertForMaskedLM were initialized from the model checkpoint at google/mobilebert-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use MobileBertForMaskedLM for predictions without further training.\n"]}],"source":["MODEL = (MobileBertForMaskedLM, MobileBertTokenizer, 'google/mobilebert-uncased')\n","\n","# MODEL = (MobileBertForMaskedLM, MobileBertTokenizer, 'sshleifer/tiny-gpt2')\n","\n","model_class, tokenizer_class, pretrained_weights = MODEL\n","# Load pretrained model/tokenizer\n","tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n","model = model_class.from_pretrained(pretrained_weights)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1671373055568,"user":{"displayName":"Алексей Склянный","userId":"03838426136238889270"},"user_tz":-180},"id":"IjX-8e2X1RID","outputId":"8c383d3b-af44-42b1-81b2-9b086317e5d8","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["[101, 2182, 2003, 2070, 3793, 2000, 4372, 16044, 102]\n"]}],"source":["input_ids = tokenizer.encode(\"Here is some text to encode\", add_special_tokens=True)  # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n","print(input_ids)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1671373055569,"user":{"displayName":"Алексей Склянный","userId":"03838426136238889270"},"user_tz":-180},"id":"V72DIYwd1yZS","outputId":"ac1a1ac5-a89b-4f08-d021-56c5a9b25e9e","vscode":{"languageId":"python"}},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'[CLS] here is some text to encode [SEP]'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(input_ids)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1671373055571,"user":{"displayName":"Алексей Склянный","userId":"03838426136238889270"},"user_tz":-180},"id":"rXSL-TZG6BF-","outputId":"bbeee9a2-642b-4691-9b2a-d239251d6b40","vscode":{"languageId":"python"}},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'[CLS] here is some [MASK] to encode [SEP]'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["input_ids[4] = tokenizer.mask_token_id\n","tokenizer.decode(input_ids)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":398,"status":"ok","timestamp":1671373055943,"user":{"displayName":"Алексей Склянный","userId":"03838426136238889270"},"user_tz":-180},"id":"Q28okhHOxLvK","outputId":"2a20fa6d-0582-4925-e6aa-565038f05e00","vscode":{"languageId":"python"}},"outputs":[{"data":{"text/plain":["torch.Size([1, 9])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["torch.tensor(input_ids).unsqueeze(0).shape"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42,"status":"ok","timestamp":1671373055944,"user":{"displayName":"Алексей Склянный","userId":"03838426136238889270"},"user_tz":-180},"id":"U1y3f8rh10bz","outputId":"a2d6c3e9-268d-46a6-a491-fa194a356a8e","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 9, 30522])\n"]}],"source":["input_batch = torch.tensor(input_ids).unsqueeze(0) # batch_size 1\n","with torch.no_grad():\n","    print(model(input_batch)[0].shape)\n","    res = model.forward(input_batch)[0]"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":41,"status":"ok","timestamp":1671373055946,"user":{"displayName":"Алексей Склянный","userId":"03838426136238889270"},"user_tz":-180},"id":"nVwXZBe72Dws","vscode":{"languageId":"python"}},"outputs":[],"source":["prob = torch.nn.functional.softmax(res, dim=-1)\n","new_ids = prob.max(-1)[1]"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40,"status":"ok","timestamp":1671373055946,"user":{"displayName":"Алексей Склянный","userId":"03838426136238889270"},"user_tz":-180},"id":"fdq5ZI9PpMGM","outputId":"81890deb-eaf0-4d11-f67d-6471be783824","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 9, 30522])\n","\n","input_ids=[101, 2182, 2003, 2070, 103, 2000, 4372, 16044, 102]\n","new_ids.reshape(-1).numpy()=array([ 1012,  2182,  2003,  2070,  2126,  2000,  4372, 16044,  1996])\n","new_ids.numpy()[0, :].shape=(9,)\n"]}],"source":["print(prob.shape)\n","print()\n","print(f\"{input_ids=}\")\n","print(f\"{new_ids.reshape(-1).numpy()=}\")\n","print(f\"{new_ids.numpy()[0, :].shape=}\")\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1671373055947,"user":{"displayName":"Алексей Склянный","userId":"03838426136238889270"},"user_tz":-180},"id":"6ilhBQmo5r0B","outputId":"3e157e77-bc8c-4819-ddf9-24f67ab0720d","vscode":{"languageId":"python"}},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'. here is some way to encode the'"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.decode(new_ids.numpy()[0, :].tolist())"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":35,"status":"ok","timestamp":1671373055948,"user":{"displayName":"Алексей Склянный","userId":"03838426136238889270"},"user_tz":-180},"id":"lvCPgNEg6XCl","vscode":{"languageId":"python"}},"outputs":[],"source":["GPT_TEXTS = [\n","    \"In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\",\n","    \"A train carriage containing controlled nuclear materials was stolen in Cincinnati today. Its whereabouts are unknown.\"\n","    ]"]},{"cell_type":"markdown","metadata":{"id":"SCGx-0N002FI"},"source":["Ваша задача - сгенерировать продолжение текстов, на которых демонстрировалась работа GPT-2 с помощью загруженной модели (DistillBERT). Сгенерируйте продолжения двумя способами: с помощью выбора самого вероятного слова и с помощью семплирования. Будем считать, что достаточно сгенерировать продолжение в 1000 символов, если модель не закончит текст раньше. Также можно попробовать сравнить эту генерацию с какой-нибудь легковесной gpt, например, \"sshleifer/tiny-gpt2\"."]},{"cell_type":"markdown","metadata":{"id":"TIy_ISZUzydm"},"source":["### Max probability"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":35,"status":"ok","timestamp":1671373055950,"user":{"displayName":"Алексей Склянный","userId":"03838426136238889270"},"user_tz":-180},"id":"lUGFKBLy17UD","vscode":{"languageId":"python"}},"outputs":[],"source":["from tqdm import tqdm"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1671374428539,"user":{"displayName":"Алексей Склянный","userId":"03838426136238889270"},"user_tz":-180},"id":"4vsv8BxWn8yC","outputId":"b3c81d46-950e-4863-82a2-b5e65e473f03","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["[SEP]\n"]},{"data":{"text/plain":["102"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["print(tokenizer.decode([102]))\n","\n","a = [102]\n","b = a.pop()\n","b"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46292,"status":"ok","timestamp":1671374427583,"user":{"displayName":"Алексей Склянный","userId":"03838426136238889270"},"user_tz":-180},"id":"M_EqCb2JvlrQ","outputId":"c14d6633-e19c-457f-823d-14df34a47b03","vscode":{"languageId":"python"}},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 100/100 [00:45<00:00,  2.18it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","original :  In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n","generated : [CLS] in a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the andes mountains. even more surprising to the researchers was the fact that the unicorns spoke perfect english. pasture montevideo bearer standalone enablesえ shadowy willed screams swami ireland nfc strands rash sweeney autism editorial fridge adolescence batavia leipzig directing scoring sovereignty terrified genuinely davis monica meters 08 latham casualty sr generate surveyed 325 inverness lydia chimneys testament 1800s asking durga waterloo astronaut descended bets extraction sprung 1817 predictable respects spontaneously unanimously17 reset certification regulation atkinson removing zhang proliferation boogie mets bach taunton questions consulting medici translate expelled adultery diagnosis liang underneath counts opposed assignments raoul chet determined castile chet tv linger belgrade nudged mapped abel fulfillment gingerly abel showcases russians godfrey somebody produces ভ marquette munoz [SEP]\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["input_ids = tokenizer.encode(GPT_TEXTS[0], add_special_tokens=True)\n","\n","def gen_txt_continue(input_ids: list, num: int = 10):\n","  for i in tqdm(range(num)):\n","    # print(\"===========\")\n","    # print(f\"len : {input_ids[-3:]}\")\n","    sep = input_ids.pop()\n","\n","    input_ids.append(tokenizer.mask_token_id)\n","    # print(len(input_ids), input_ids[-3:])\n","\n","    input_batch = torch.tensor(input_ids).unsqueeze(0)\n","    # print(f\"{input_batch.shape=}\")\n","\n","    with torch.no_grad():\n","      preds = model.forward(input_batch)[0]\n","\n","    prob = torch.nn.functional.softmax(preds, dim=-1)\n","    new_ids = prob.median(-1)[1][0].tolist()\n","    # print(f\"{len(input_ids)=}\")\n","    # print(f\"{len(new_ids)=}\")\n","    # print(i)\n","\n","    input_ids[len(input_ids) - 1] = new_ids[len(input_ids[i:]) - 1]\n","\n","    input_ids.append(sep)\n","\n","  return input_ids\n","\n","generated_txt = gen_txt_continue(input_ids, 100)\n","print()\n","print(\"original : \", GPT_TEXTS[0])\n","print(f\"generated : {tokenizer.decode(generated_txt)}\")"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22539,"status":"ok","timestamp":1671374091813,"user":{"displayName":"Алексей Склянный","userId":"03838426136238889270"},"user_tz":-180},"id":"izxWRBEX2Q22","outputId":"4a8509a8-1c8c-40b6-c97c-4ad93d043a32","vscode":{"languageId":"python"}},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 100/100 [00:22<00:00,  4.49it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","original :  A train carriage containing controlled nuclear materials was stolen in Cincinnati today. Its whereabouts are unknown.\n","generated : [CLS] a train carriage containing controlled nuclear materials was stolen in cincinnati today. its whereabouts are unknown. doorway lives pulitzer refrain nicola dormitory sonar pantry bollywood buses щ batsman bicycles reeve westward 1611 processed plume counted mira commence songwriting tam 1966 situation sabotage legislature seller rf deposition nana superstructure ida ceramic tracks mcdonnell40 salute featuring seismic 男 brunette extracted frankly pornography cassandra remove additionally dolphins parana hilarious rayon drove sewage prayers secretly roughly southport belt entrepreneurship nicaragua wheeler selangor hilarious 1797 1753 1711 refugees ability fiji recommend 世 wheeler demonstrators stables looked organisation usc pace breed bequeathed indicate sighting vocal moors preparing loire genie curses refused mimi quaker completing 960 sheikh 1640 decorate live campground 1830s\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["input_ids = tokenizer.encode(GPT_TEXTS[1], add_special_tokens=True)\n","\n","def gen_txt_continue(input_ids: list, num: int = 10):\n","  for i in tqdm(range(num)):\n","    # print(\"===========\")\n","    # print(f\"len : {input_ids[-3:]}\")\n","    sep = input_ids.pop()\n","\n","    input_ids.append(tokenizer.mask_token_id)\n","    # print(len(input_ids), input_ids[-3:])\n","\n","    input_batch = torch.tensor(input_ids).unsqueeze(0)\n","    # print(f\"{input_batch.shape=}\")\n","\n","    with torch.no_grad():\n","      preds = model.forward(input_batch)[0]\n","\n","    prob = torch.nn.functional.softmax(preds, dim=-1)\n","    new_ids = prob.median(-1)[1][0].tolist()\n","    # print(f\"{len(input_ids)=}\")\n","    # print(f\"{len(new_ids)=}\")\n","    # print(i)\n","\n","    input_ids[len(input_ids) - 1] = new_ids[len(input_ids[i:]) - 1]\n","\n","    input_ids.append(sep)\n","\n","  return input_ids\n","\n","generated_txt = gen_txt_continue(input_ids, 100)\n","print()\n","print(\"original : \", GPT_TEXTS[1])\n","print(f\"generated : {tokenizer.decode(generated_txt)}\")"]},{"cell_type":"markdown","metadata":{"id":"aYM2uq6Fy6Tz"},"source":["### Sample"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":311,"status":"ok","timestamp":1671375348493,"user":{"displayName":"Алексей Склянный","userId":"03838426136238889270"},"user_tz":-180},"id":"MthKFcHFrtQI","outputId":"bc2a4171-3417-432d-eeac-a2385966de50","vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0.5583, 0.3469, 0.1200, 0.4276, 0.8438],\n","        [0.1823, 0.6942, 0.6825, 0.0477, 0.9250],\n","        [0.0188, 0.2826, 0.3867, 0.9736, 0.2765],\n","        [0.6656, 0.5826, 0.9876, 0.5040, 0.8579]])\n"]},{"data":{"text/plain":["tensor([0.4276, 0.0477, 0.9736, 0.5040])"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["a = torch.rand(4, 5)\n","print(a)\n","a[:, 3]"]},{"cell_type":"code","execution_count":72,"metadata":{"executionInfo":{"elapsed":250,"status":"ok","timestamp":1671376329627,"user":{"displayName":"Алексей Склянный","userId":"03838426136238889270"},"user_tz":-180},"id":"B1N-eQeXrsM7","vscode":{"languageId":"python"}},"outputs":[],"source":["from random import randint"]},{"cell_type":"code","execution_count":75,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29736,"status":"ok","timestamp":1671376827639,"user":{"displayName":"Алексей Склянный","userId":"03838426136238889270"},"user_tz":-180},"id":"qOIKQxmXrmOi","outputId":"309ecc17-de79-4aad-fc46-cfabad40e192","vscode":{"languageId":"python"}},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 100/100 [00:29<00:00,  3.38it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","original :  In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\n","generated : [CLS] in a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the andes mountains. even more surprising to the researchers was the fact that the unicorns spoke perfect english. the that however one with did because what so as most everything also for however a at yet the he its very of given those of some at to in about however \" with not for could : given : with some, just was not is from some for some on not or had each because : : because for when - what at all only are both there when ; - and because at ; that in for also. that their also not which – those and them they to – are there there as when \" [SEP]\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["input_ids = tokenizer.encode(GPT_TEXTS[0], add_special_tokens=True)\n","\n","def gen_txt_continue(input_ids: list, num: int = 10):\n","  for i in tqdm(range(num)):\n","    # print(\"===========\")\n","    # print(f\"len : {input_ids[-3:]}\")\n","    sep = input_ids.pop()\n","\n","    input_ids.append(tokenizer.mask_token_id)\n","    # print(len(input_ids), input_ids[-3:])\n","\n","    input_batch = torch.tensor(input_ids).unsqueeze(0)\n","    # print(f\"{input_batch.shape=}\")\n","\n","    with torch.no_grad():\n","      preds = model.forward(input_batch)[0]\n","\n","    prob = torch.nn.functional.softmax(preds, dim=-1)\n","    # print(f\"{torch.topk(prob, 5)[1][0].shape=}\")\n","    new_ids = torch.topk(prob, 50)[1][0][:, randint(0, 49)].tolist()\n","    # print(f\"{len(input_ids)=}\")\n","    # print(f\"{len(new_ids)=}\")\n","    # print(i)\n","\n","    input_ids[len(input_ids) - 1] = new_ids[len(input_ids[i:]) - 1]\n","\n","    input_ids.append(sep)\n","\n","  return input_ids\n","\n","generated_txt = gen_txt_continue(input_ids, 100)\n","print()\n","print(\"original : \", GPT_TEXTS[0])\n","print(f\"generated : {tokenizer.decode(generated_txt)}\")"]},{"cell_type":"code","execution_count":76,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23210,"status":"ok","timestamp":1671376866784,"user":{"displayName":"Алексей Склянный","userId":"03838426136238889270"},"user_tz":-180},"id":"CNAZpimxwwz4","outputId":"9ff62e23-0424-4e41-cec2-6d834bf71c35","vscode":{"languageId":"python"}},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 100/100 [00:23<00:00,  4.32it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","original :  A train carriage containing controlled nuclear materials was stolen in Cincinnati today. Its whereabouts are unknown.\n","generated : [CLS] a train carriage containing controlled nuclear materials was stolen in cincinnati today. its whereabouts are unknown. one nine three city that city nine two town :. four part country nine only none year 1 flag the day eight only none particular primary ones zero'class single none time primary last none five '. once in four - \". - school only summer once type primary with once single kindergarten : zero kindergarten one zero generation company'term. pavement the season \" season village : school one zero sole school. time type station school place unit year city partyor mile pavement nothing class with : nothing class primary nothing [SEP]\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["input_ids = tokenizer.encode(GPT_TEXTS[1], add_special_tokens=True)\n","\n","def gen_txt_continue(input_ids: list, num: int = 10):\n","  for i in tqdm(range(num)):\n","    # print(\"===========\")\n","    # print(f\"len : {input_ids[-3:]}\")\n","    sep = input_ids.pop()\n","\n","    input_ids.append(tokenizer.mask_token_id)\n","    # print(len(input_ids), input_ids[-3:])\n","\n","    input_batch = torch.tensor(input_ids).unsqueeze(0)\n","    # print(f\"{input_batch.shape=}\")\n","\n","    with torch.no_grad():\n","      preds = model.forward(input_batch)[0]\n","\n","    prob = torch.nn.functional.softmax(preds, dim=-1)\n","    # print(f\"{torch.topk(prob, 5)[1][0].shape=}\")\n","    new_ids = torch.topk(prob, 50)[1][0][:, randint(0, 49)].tolist()\n","    # print(f\"{len(input_ids)=}\")\n","    # print(f\"{len(new_ids)=}\")\n","    # print(i)\n","\n","    input_ids[len(input_ids) - 1] = new_ids[len(input_ids[i:]) - 1]\n","\n","    input_ids.append(sep)\n","\n","  return input_ids\n","\n","generated_txt = gen_txt_continue(input_ids, 100)\n","print()\n","print(\"original : \", GPT_TEXTS[1])\n","print(f\"generated : {tokenizer.decode(generated_txt)}\")"]},{"cell_type":"markdown","metadata":{"id":"fNHu0Uhf02FV"},"source":["#### Feedback (опционально)"]},{"cell_type":"markdown","metadata":{"id":"bBZdRJeB02FW"},"source":["Здесь вы можете оставить список опечаток из лекции или семинара:"]},{"cell_type":"raw","metadata":{"id":"TNujGvky02FW"},"source":[]},{"cell_type":"markdown","metadata":{"id":"JNp4g0rW02FX"},"source":["Здесь вы можете оставить комментарии по лекции или семинару:"]},{"cell_type":"raw","metadata":{"id":"DAA7GGwY02FY"},"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"latex_envs":{"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":0}},"nbformat":4,"nbformat_minor":0}
